# Detecci√≥n de Fraude con Machine Learning

Este proyecto implementa un sistema avanzado de detecci√≥n de fraude en transacciones financieras utilizando t√©cnicas de machine learning. Combina aprendizaje supervisado con detecci√≥n de anomal√≠as no supervisada para identificar transacciones fraudulentas en el dataset IEEE-CIS Fraud Detection.

## üìã Descripci√≥n del Proyecto

El sistema est√° dise√±ado como una plantilla para experimentaci√≥n y uso en producci√≥n, con una arquitectura modular que facilita el mantenimiento y la extensi√≥n. Utiliza el dataset de Kaggle IEEE-CIS Fraud Detection, que contiene datos de transacciones e-commerce con caracter√≠sticas an√≥nimas y etiquetas de fraude.

### üéØ Objetivo

Desarrollar un modelo robusto que pueda detectar transacciones fraudulentas en tiempo real, combinando m√∫ltiples t√©cnicas de machine learning para maximizar la precisi√≥n y minimizar los falsos positivos.

## üìä Dataset Utilizado

**IEEE-CIS Fraud Detection Dataset** ([Enlace a Kaggle](https://www.kaggle.com/competitions/ieee-fraud-detection/data?select=train_transaction.csv))

### Estructura de Datos:

- **`train_transaction.csv`**: Datos principales de transacciones (~590k filas)

  - `TransactionID`: ID √∫nico de la transacci√≥n
  - `isFraud`: Etiqueta objetivo (0 = leg√≠tima, 1 = fraudulenta)
  - `TransactionDT`: Timestamp de la transacci√≥n (segundos desde referencia)
  - `TransactionAmt`: Monto de la transacci√≥n
  - `ProductCD`: C√≥digo del producto
  - `card1-card6`: Informaci√≥n de la tarjeta (an√≥nima)
  - `addr1-addr2`: Direcciones del comprador
  - `dist1-dist2`: Distancias
  - `P_emaildomain`, `R_emaildomain`: Dominios de email
  - `C1-C14`: Features de conteo
  - `D1-D15`: Features de tiempo/delay
  - `M1-M9`: Features de matching
  - `V1-V339`: Features an√≥nimas (principalmente num√©ricas)

- **`train_identity.csv`**: Datos de identidad (~140k filas)
  - Informaci√≥n del dispositivo y navegador
  - `id_01` to `id_38`: Features de identidad an√≥nimas
  - `DeviceType`, `DeviceInfo`: Tipo e info del dispositivo

### Distribuci√≥n de Clases:

- Transacciones leg√≠timas: ~96.5%
- Transacciones fraudulentas: ~3.5%
- Ratio de desbalance: ~27:1

## üèóÔ∏è Arquitectura del Sistema

### Estructura de Directorios

```
deteccion-de-fraude/
‚îú‚îÄ‚îÄ data/                      # Archivos de datos
‚îÇ   ‚îú‚îÄ‚îÄ train_transaction.csv  # Datos de entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ train_identity.csv     # Datos de identidad entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ test_transaction.csv   # Datos de prueba
‚îÇ   ‚îú‚îÄ‚îÄ test_identity.csv      # Datos de identidad prueba
‚îÇ   ‚îî‚îÄ‚îÄ new_transactions.csv   # Nuevas transacciones para predicci√≥n
‚îú‚îÄ‚îÄ models/                    # Modelos entrenados y encoders
‚îÇ   ‚îú‚îÄ‚îÄ lightgbm_fold[1-5].pkl # Modelos LightGBM (5-fold CV)
‚îÇ   ‚îú‚îÄ‚îÄ isoforest.joblib       # Modelo Isolation Forest
‚îÇ   ‚îú‚îÄ‚îÄ target_encoder_full.joblib # Encoder categ√≥rico global
‚îÇ   ‚îú‚îÄ‚îÄ pca_full.joblib        # PCA para features V
‚îÇ   ‚îú‚îÄ‚îÄ pca_fold[1-5].joblib   # PCA por fold
‚îÇ   ‚îú‚îÄ‚îÄ selected_features.pkl  # Lista de features seleccionadas
‚îÇ   ‚îî‚îÄ‚îÄ decision_threshold.pkl # Umbral √≥ptimo de decisi√≥n
‚îú‚îÄ‚îÄ outputs/                   # Resultados y m√©tricas
‚îÇ   ‚îú‚îÄ‚îÄ evaluation_metrics.json # M√©tricas de evaluaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ new_predictions.csv    # Predicciones en nuevas transacciones
‚îú‚îÄ‚îÄ src/                       # C√≥digo fuente modular
‚îÇ   ‚îú‚îÄ‚îÄ preprocess.py          # Funciones de preprocesamiento
‚îÇ   ‚îú‚îÄ‚îÄ feature_engineering.py # Ingenier√≠a de features
‚îÇ   ‚îî‚îÄ‚îÄ anomaly_isoforest.py   # Detecci√≥n de anomal√≠as
‚îú‚îÄ‚îÄ main_train.py              # Script principal de entrenamiento
‚îú‚îÄ‚îÄ predict_new.py             # Script de predicci√≥n
‚îú‚îÄ‚îÄ requirements.txt           # Dependencias Python
‚îú‚îÄ‚îÄ docs.md                    # Documentaci√≥n t√©cnica detallada
‚îî‚îÄ‚îÄ README.md                  # Este archivo
```

### Pipeline de Procesamiento

1. **Ingesta de Datos**: Carga y merge de datos de transacciones e identidad
2. **Preprocesamiento**: Limpieza, imputaci√≥n de valores faltantes, encoding categ√≥rico
3. **Ingenier√≠a de Features**: Transformaciones, agregaciones, reducci√≥n dimensional
4. **Entrenamiento**: Modelos supervisados (LightGBM) + no supervisados (Isolation Forest)
5. **Predicci√≥n**: Aplicaci√≥n de modelos entrenados a nuevos datos
6. **Evaluaci√≥n**: M√©tricas de performance y validaci√≥n

## ‚öôÔ∏è Requisitos para Ejecutar el Entrenamiento

### Dependencias

```
pandas>=1.3.0
numpy>=1.21.0
scikit-learn>=1.0.0
lightgbm>=3.3.0
category_encoders>=2.3.0
joblib>=1.1.0
tqdm>=4.62.0
shap>=0.40.0
matplotlib>=3.5.0
seaborn>=0.11.0
```

### Instalaci√≥n

```bash
pip install -r requirements.txt
```

### Requisitos de Hardware

- **RAM**: M√≠nimo 16GB, recomendado 32GB+
- **CPU**: Multi-core recomendado (el c√≥digo usa `n_jobs=-1`)
- **Almacenamiento**: ~5GB para datos + modelos
- **GPU**: Opcional (LightGBM puede usar GPU para entrenamiento m√°s r√°pido)

### Requisitos de Datos

1. Descargar el dataset de Kaggle y colocar los archivos en `data/`:

   - `train_transaction.csv`
   - `train_identity.csv`
   - `test_transaction.csv` (opcional)
   - `test_identity.csv` (opcional)

2. Para predicciones, crear `data/new_transactions.csv` con el script new_transaction.py

## üöÄ C√≥mo Usar el Sistema

### 1. Preparaci√≥n de Datos

```bash
# Descargar dataset de Kaggle y colocar en data/
# Asegurarse de que los archivos est√©n en el directorio correcto
ls data/
# train_transaction.csv  train_identity.csv  test_transaction.csv  test_identity.csv
```

### 2. Entrenamiento del Modelo

```bash
python main_train.py
```

**Qu√© hace el entrenamiento:**

- Carga y preprocesa los datos
- Aplica ingenier√≠a de features
- Entrena 5 modelos LightGBM con cross-validation estratificada
- Entrena Isolation Forest para detecci√≥n de anomal√≠as
- Calcula umbral √≥ptimo de decisi√≥n
- Guarda todos los modelos y m√©tricas

**Tiempo estimado**: ~30-60 minutos dependiendo del hardware

### 3. Predicci√≥n en Nuevas Transacciones

```bash
python predict_new.py
```

**Proceso de predicci√≥n:**

- Carga nuevas transacciones desde `data/new_transactions.csv`
- Aplica el mismo preprocesamiento y feature engineering
- Genera predicciones con LightGBM + Isolation Forest
- Combina scores con l√≥gica de decisi√≥n
- Guarda resultados en `outputs/new_predictions.csv`

## üîß Detalles del Entrenamiento

### Estrategia de Validaci√≥n

- **Time-based Split**: Entrenamiento en 80% temporal temprano, validaci√≥n en 20% temporal tard√≠o
- **5-Fold Cross-Validation**: Dentro del conjunto de entrenamiento para evaluaci√≥n robusta
- **Prevenci√≥n de Data Leakage**: Encoding y PCA ajustados por fold para evitar contaminaci√≥n

### Features Engineering

1. **Transformaciones B√°sicas**:

   - Log-transform del monto de transacci√≥n (`TransactionAmt_log`)
   - Features temporales: `hour`, `day` desde `TransactionDT`

2. **Agregaciones por Tarjeta**:

   - Media y desviaci√≥n est√°ndar de montos por `card1`
   - Ratio del monto actual vs. media hist√≥rica

3. **Reducci√≥n Dimensional**:

   - PCA en features V (339 ‚Üí 20 componentes)
   - Selecci√≥n de top 300 features por varianza

4. **Encoding Categ√≥rico**:
   - Target Encoding para categor√≠as con <200 valores √∫nicos
   - Smoothing para evitar overfitting

### Modelos Utilizados

#### LightGBM (Supervisado)

- **Objetivo**: `binary` (clasificaci√≥n binaria)
- **M√©trica**: AUC
- **Hiperpar√°metros**:
  - `learning_rate`: 0.03
  - `num_leaves`: 128
  - `feature_fraction`: 0.8
  - `bagging_fraction`: 0.8
  - `lambda_l1/lambda_l2`: 0.5
  - `min_data_in_leaf`: 30
- **Entrenamiento**: 4000 iteraciones con early stopping (100 rondas)

#### Isolation Forest (No Supervisado)

- **Contaminaci√≥n**: 1% (esperado ratio de anomal√≠as)
- **Estimators**: 200 √°rboles
- **Random State**: 42

### M√©tricas de Performance

- **OOF AUC**: 0.953 (Cross-validation en entrenamiento)
- **Holdout AUC**: 0.921 (Validaci√≥n temporal)
- **Best Threshold**: 0.215 (√≥ptimo para F1-score)
- **Best F1-Score**: 0.753

### Criterios de Entrenamiento

1. **Robustez Temporal**: Validaci√≥n en datos futuros para simular producci√≥n
2. **Prevenci√≥n de Overfitting**: Regularizaci√≥n L1/L2, feature selection, early stopping
3. **Manejo de Desbalance**: Estratificaci√≥n en CV, evaluaci√≥n con F1-score
4. **Eficiencia Computacional**: PCA para reducci√≥n dimensional, paralelizaci√≥n
5. **Interpretabilidad**: Features seleccionadas por varianza, posibilidad de SHAP

## üìà Resultados y Evaluaci√≥n

### M√©tricas Principales

```json
{
  "oof_auc": 0.9529786660279241,
  "val_auc": 0.9210964511516676,
  "best_threshold": 0.2152629992636282,
  "best_f1": 0.753071671862922
}
```

### Interpretaci√≥n

- **AUC Alto**: Excelente capacidad discriminativa
- **F1-Score**: Buen balance precision/recall para clase minoritaria
- **Threshold √ìptimo**: Calibrado para maximizar F1 en datos de validaci√≥n

### Predicciones en Nuevas Transacciones

El sistema genera:

- `fraud_probability`: Score de LightGBM (0-1)
- `anomaly_score`: Score de Isolation Forest (m√°s negativo = m√°s an√≥malo)
- `is_fraud_pred`: Decisi√≥n final (1 = fraudulento, 0 = leg√≠timo)

**L√≥gica de Decisi√≥n Final**:

```python
fraud_flags = (fraud_probability >= threshold) | (anomaly_score < -0.2)
```

## üîç An√°lisis del C√≥digo

### Scripts Principales

#### `main_train.py`

Orquesta todo el pipeline de entrenamiento:

- Carga y merge de datos
- Preprocesamiento b√°sico
- Split temporal train/holdout
- Feature engineering
- Entrenamiento con CV
- Evaluaci√≥n y guardado

#### `predict_new.py`

Pipeline de inferencia:

- Carga nuevas transacciones
- Aplicaci√≥n de transformaciones aprendidas
- Predicciones ensemble
- Guardado de resultados

### M√≥dulos Core

#### `src/preprocess.py`

- `basic_clean()`: Limpieza de datos, normalizaci√≥n
- `basic_impute()`: Imputaci√≥n de valores faltantes
- `fit_target_encoder()`: Ajuste de encoding categ√≥rico
- `apply_target_encoding()`: Aplicaci√≥n de encoding

#### `src/feature_engineering.py`

- `log_transform_amount()`: Transformaci√≥n logar√≠tmica
- `create_time_features()`: Extracci√≥n de features temporales
- `card_agg_features()`: Agregaciones por tarjeta
- `reduce_V_features_pca()`: Reducci√≥n dimensional con PCA
- `select_features()`: Selecci√≥n por varianza

#### `src/anomaly_isoforest.py`

- `train_isolation_forest()`: Entrenamiento del modelo no supervisado.

## üéØ Mejoras Futuras

1. **Hiperparameter Tuning**: Optimizaci√≥n autom√°tica de par√°metros
2. **Features Adicionales**: Interacciones, embeddings, features temporales avanzadas
3. **Modelos Ensemble**: Combinaci√≥n de m√∫ltiples algoritmos
4. **Real-time Scoring**: API para predicciones en tiempo real
5. **Monitoring**: Sistema de monitoreo de performance en producci√≥n
6. **Explainability**: An√°lisis SHAP para interpretabilidad

## üìù Notas Importantes

- El sistema est√° optimizado para el dataset IEEE-CIS espec√≠fico
- Los features V son an√≥nimos pero cruciales para la performance
- El threshold √≥ptimo puede requerir ajuste seg√∫n el caso de uso espec√≠fico
- Para producci√≥n, considerar validaci√≥n adicional y monitoring continuo

## ü§ù Contribuci√≥n

Este proyecto est√° dise√±ado para ser extensible. Las mejoras sugeridas incluyen:

- Nuevos algoritmos de ML
- Features engineering adicionales
- Mejores estrategias de validaci√≥n
- Optimizaciones de performance

## üìÑ Licencia

Este proyecto es para fines educativos y de investigaci√≥n. El dataset IEEE-CIS tiene sus propias condiciones de uso a trav√©s de Kaggle.
