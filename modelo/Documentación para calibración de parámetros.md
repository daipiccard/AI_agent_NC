# ğŸ§  DocumentaciÃ³n de CalibraciÃ³n de ParÃ¡metros â€” DetecciÃ³n de Fraude

Excelente pregunta ğŸ‘  
Este documento explica **en espaÃ±ol y con detalle** cÃ³mo calibrar los **parÃ¡metros e hiperparÃ¡metros** del modelo de detecciÃ³n de fraude, ademÃ¡s de la configuraciÃ³n de validaciÃ³n para obtener un rendimiento mÃ¡s realista y estable.

---

## ğŸ§© 1. Estrategia de divisiÃ³n de datos (Data Splitting & Validation)

### ğŸ”¹ DivisiÃ³n temporal ("Time-based Split")

- **QuÃ© hace:** divide los datos segÃºn el **tiempo** (por ejemplo, por el dÃ­a de la transacciÃ³n).
- **CÃ³mo se define:** se toma el percentil 80 del campo `day` â†’ todo lo anterior al dÃ­a 58 se usa para **entrenar**, y lo posterior para **validar**.
- **Por quÃ© se hace:** esto **evita fugas de datos del futuro** ("data leakage"), asegurando que el modelo solo vea transacciones anteriores, no futuras.

**Ejemplo:**

- Transacciones del dÃ­a 1 al 58 â†’ entrenamiento (80%)
- Transacciones del dÃ­a 58 al 73 â†’ validaciÃ³n (20%)

ğŸ“˜ Esto imita cÃ³mo el modelo se usarÃ¡ en producciÃ³n: entrenas con el pasado y predices el futuro.

---

### ğŸ”¹ ValidaciÃ³n cruzada estratificada (Stratified K-Fold)

- **QuÃ© es:** divide los datos de entrenamiento en 5 partes (folds), manteniendo la proporciÃ³n de fraudes y no fraudes en cada una.
- **PropÃ³sito:** obtener un rendimiento mÃ¡s estable y evitar sobreajuste ("overfitting").
- **ParÃ¡metros:**
  - `n_splits = 5`
  - `shuffle = True` (mezcla las filas)
  - `random_state = 42` (reproducibilidad)

ğŸ“˜ Esto permite obtener un valor medio del rendimiento del modelo en distintos subconjuntos de los datos (OOF = Out Of Fold).

---

## âš™ï¸ 2. ParÃ¡metros de _Feature Engineering_

### ğŸ”¹ PCA (ReducciÃ³n de dimensionalidad)

- **QuÃ© hace:** toma las columnas `V1, V2, ..., V339` y las resume en **20 componentes** principales.
- **Objetivo:** reducir ruido y correlaciones redundantes, acelerando el entrenamiento.
- **Modo entrenamiento:** el PCA se ajusta solo con los datos de _train_ (para evitar fuga de datos).
- **Valores faltantes:** se rellenan con `-1`.

ğŸ“˜ Ejemplo: en lugar de 339 columnas "V", se usan 20 que resumen la variaciÃ³n principal.

---

### ğŸ”¹ SelecciÃ³n de features (Feature Selection)

- **MÃ©todo:** se eligen las **300 columnas con mayor varianza** (las mÃ¡s informativas).
- **ExclusiÃ³n:** se ignoran `TransactionID`, `isFraud` y columnas no numÃ©ricas.
- **Orden:** de mayor a menor varianza.

ğŸ“˜ Esto elimina columnas con poca informaciÃ³n o ruido, mejorando velocidad y generalizaciÃ³n.

---

### ğŸ”¹ CodificaciÃ³n categÃ³rica (Target Encoding)

- **QuÃ© hace:** reemplaza categorÃ­as (por ejemplo, "tipo de dispositivo") por la **probabilidad media de fraude** asociada a esa categorÃ­a.
- **ParÃ¡metros:**
  - `smoothing = 0.3` (suaviza el efecto de categorÃ­as con pocos datos)
  - Solo se codifican columnas con menos de 200 valores Ãºnicos.
  - CategorÃ­as desconocidas â†’ se reemplazan por `'missing'`.

ğŸ“˜ Ejemplo:  
Si "browser = Chrome" tiene 2% de fraude y "browser = IE" 6%, se reemplaza el texto por esos valores numÃ©ricos.

---

## âš¡ 3. HiperparÃ¡metros de LightGBM

```python
lgb_params = {
    'objective': 'binary',        # clasificaciÃ³n binaria (fraude o no)
    'boosting_type': 'gbdt',      # tipo de boosting
    'metric': 'auc',              # mÃ©trica principal
    'learning_rate': 0.03,        # velocidad de aprendizaje
    'num_leaves': 128,            # complejidad de los Ã¡rboles
    'feature_fraction': 0.8,      # fracciÃ³n de features usadas por iteraciÃ³n
    'bagging_fraction': 0.8,      # fracciÃ³n de datos usados por iteraciÃ³n
    'bagging_freq': 5,            # frecuencia del bagging
    'lambda_l1': 0.5,             # regularizaciÃ³n L1
    'lambda_l2': 0.5,             # regularizaciÃ³n L2
    'min_data_in_leaf': 30,       # mÃ­nimo de datos por hoja
    'verbosity': -1,
    'seed': 42,
    'n_jobs': -1
}
```

### Entrenamiento:

num_boost_round = 4000 (mÃ¡ximo nÃºmero de Ã¡rboles)

early_stopping_rounds = 100 (si no mejora el AUC por 100 iteraciones, se detiene)

EvalÃºa cada 200 rondas para monitorear progreso

ğŸ“˜ Este balancea velocidad y generalizaciÃ³n del modelo.

---

## ğŸ§© 4. Isolation Forest (para detectar anomalÃ­as)

Detecta comportamientos raros que podrÃ­an ser fraudes.

ParÃ¡metros:

n_estimators = 200

contamination = 0.01 â†’ espera que el 1% sean anÃ³malos

random_state = 42

n_jobs = -1 (usa todos los nÃºcleos)

ğŸ“˜ Este paso ayuda a crear una feature extra que mide "quÃ© tan anÃ³mala" es una transacciÃ³n.

---

## ğŸ¯ 5. CalibraciÃ³n del Umbral (Threshold)

El modelo predice probabilidades (ej. 0.82 = posible fraude), pero hay que definir a partir de quÃ© valor se considera "fraude".

Se busca el umbral Ã³ptimo que maximiza el F1-score
(balance entre precisiÃ³n y recall).

FÃ³rmula:

F1 = 2 _ (precision _ recall) / (precision + recall)

En tu modelo actual:

Threshold Ã³ptimo = 0.2153

F1 = 0.7531

ğŸ“˜ Es decir: si la probabilidad > 0.2153, el modelo marca la transacciÃ³n como fraude.

---

## ğŸ“Š 6. MÃ©tricas Actuales

| MÃ©trica               | DescripciÃ³n                                                  | Valor  |
| --------------------- | ------------------------------------------------------------ | ------ |
| OOF AUC (Out-of-Fold) | AUC promedio en los folds de entrenamiento                   | 0.9530 |
| Holdout AUC           | AUC en el conjunto final de validaciÃ³n (simula datos nuevos) | 0.9211 |
| Best F1               | Mejor balance entre precisiÃ³n y recall                       | 0.7531 |

ğŸ“˜ InterpretaciÃ³n:

Tu modelo generaliza bien (AUC 0.92 en datos no vistos).

Pero todavÃ­a hay espacio para mejorar el F1, afinando el umbral o los pesos de clases.

---

## ğŸ§  7. Recomendaciones para CalibraciÃ³n

### ğŸ”¹ Ajustar hiperparÃ¡metros

Prueba combinaciones para encontrar el mejor equilibrio entre complejidad y sobreajuste:

learning_rate: [0.01, 0.03, 0.05, 0.1]

num_leaves: [64, 128, 256]

feature_fraction / bagging_fraction: [0.6, 0.8, 1.0]

lambda_l1 / lambda_l2: [0.1, 0.5, 1.0]

### ğŸ”¹ Tuning de features

PCA: prueba 10, 20, 30, 50 componentes

SelecciÃ³n de features: 200, 300 o 500 columnas

Target encoding smoothing: 0.1, 0.3, 0.5, 1.0

### ğŸ”¹ ValidaciÃ³n realista

MantÃ©n la divisiÃ³n temporal

Considera validaciÃ³n con ventana deslizante (rolling window) para detectar drift (cambios de comportamiento en el tiempo)

EvalÃºa no solo F1, sino tambiÃ©n costo-beneficio (ej. pÃ©rdida por falsos negativos)

---

## ğŸ En resumen

Este documento describe cÃ³mo controlar y optimizar todos los aspectos del entrenamiento:

- DivisiÃ³n temporal â†’ evita fugas de datos
- ValidaciÃ³n estratificada â†’ robustez
- PCA + selecciÃ³n â†’ eficiencia
- Target encoding â†’ mejor manejo de categorÃ­as
- LightGBM optimizado â†’ buen AUC
- Umbral calibrado â†’ buen F1
- Ajustes finos â†’ mejor rendimiento realista
